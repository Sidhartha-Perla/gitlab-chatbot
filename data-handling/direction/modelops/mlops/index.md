---
layout: sec_direction
title: "Group Direction - MLOps"
description: "Focused on enabling data teams to build, test, and deploy their machine learning models"
---

## On this page
{:.no_toc}

- TOC
{:toc}

# MLOps

| | |
| --- | --- |
| Stage | [ModelOps](/direction/modelops/) |
| Maturity | [minimal](/direction/#maturity) |
| Content Last Reviewed | `2024-10-05` |


## Overview

Machine Learning Operations (MLOps) aims to bring together data exploration, experimentation, evaluation, deployment, management, and automation of machine learning models in production reliably and efficiently. 

![MLOps Concept Map](MLOpsConceptMap.png)

The concept map above shows the key activities of MLOps, mapped to the user personas, and mapped to the tools and capabilities that help users accomplish those activities.
You can further explore this [MLOps concept map](https://www.figma.com/file/gWegSkebhBXYdPxfkvT7LY/ModelOps-Concept-Map?type=whiteboard&node-id=0%3A1&t=3WCkMxPXSEiaJhBf-1) (along with DataOps and LLMOps).  
or watch the accompanying [overview video](https://youtu.be/74tpoTUMmeY).

## Vision

Data Scientist, ML Engineers, and stakeholders work together in GitLab to experiment, evaluate, verify, deploy, monitor and keep models secure and up-to-date. Their processes are reproducible, automated, collaborative, scalable, and monitored. 

They further collaborate with other product development teams in GitLab so that there is tight coordination between models and their dependent applications. Teams stay informed on status of various components and can seamlessly coordinate making changes to production systems.

### Why is GitLab suitable for MLOPs?

Like software development, machine learning and model development benefit from automation and collaboration to consistently and iteratively deliver value. As machine learning becomes more prevalent, the number of individuals, roles, and frequency of changes increases. This causes friction and often results in costly errors. Instead of maintaining siloed workflows, bringing ML workflows into GitLab as a single collaboration platform extends the DevSecOps culture to data scientists, helping organizations achieve better results.

## Roadmap

Over the course of FY25, GitLab ramped up a team dedicated to MLOps. They are focused on the core of managing models and their versions, along with developing a MVC of model deployment. 

### Model Registry 

Succeeding with complex AI/ML workflows centers around managing models. Data scientists experiment and create model candidates, after validation candidates are promoted to models destined for production software. These promoted models need to be tracked and version just as any other code in a software project to ensure governance with any model workflows. As these models change over time the lineage of the data they were trained on, the source code they were generated with, and the software versions they are deployed into all needs to be tracked to produce lineage of the model for proper compliance and governance. A model registry is central to all these tasks and is the fundamental aspect of MLOPs. Everything we build to support AI/ML workflows will integrate to and from the model registry. 

### Model Deployment 

Once models are versioned and tracked, they need to be deployed. This allows models to be excercised for evaluation to ensure they produce expected results but also to ensure that they operate as intended. We'll built an automated model deployment platform built atop the model registry to make it easy for the model registry to trigger GitLab CI/CD and enable dynamic evaluation within CI jobs. By doing this, models can be built, tested, and deployed just like any other part of a software system, all with automated CI/CD, source code management, and even security testing. 

Our vision for model deploymnet will allow data scientists and software engineers to work together more seemlessly to build AI/ML powered software that powers our world.  

### Observability 

Once models are deployed, whether in development, staging, or production, they need to be tracked and observed for quality, performance, and model drift. Leveraging existing observability capabilieis within the GitLab platform, we'll extend observability to models managed and deployed by GitLab. This will allow data scientists to easily excercise and test model candidates and ensure they are operating as expected. This will also make it easier to track model drift and automate how problems with models are addressed, even when running in production. 

### LLMOps 

The rise of large language models (LLMs) has further complicated the AI/ML space with even larger models, continuous data training NEEDS, high velocity changes, and increased utilization of AI/ML models in production software. GitLab intends to help customers build, personalize, and operate LLMs. We'll share more in 2025 as this space develops.  

### DevSecMLOps 

With our MLOps capabilities integrated into the wider DevSecOps platform, GitLab will bring data scientists, software engineers, and DevOps engineers into closer collaboration. It will enable these different personas to work more smoothly together and enhance the feedback loop between AI development and traditional software development. Additionally it'll bring the best practices of DevOps to AI/ML workloads improving how enterprises build next generation software powered by AI/ML systems. 


